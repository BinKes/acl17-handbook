We present two systems for the task of morphological inflection, i.e., finding a target morphological form, given a lemma and a set of target tags. Both systems are trained on datasets of three sizes: low, medium and high. The first system uses a simple Long Short-Term Memory (LSTM) for low-sized dataset, while it uses an encoder-decoder based model for the medium and high sized datasets. The second system uses a simple Gated Recurrent Unit (henceforth, GRU) for low-sized data, while it uses a combination of simple LSTMs, simple GRUs, stacked (deep) GRUs and encoder-decoder models, depending on the language, for medium-sized data. Even though the systems are not very complex, they give accuracies above baseline accuracies on high-sized datasets, above or around baseline accuracies for medium-sized datasets but mostly accuracies lower than baseline for low-sized datasets.
