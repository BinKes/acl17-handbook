Social media accumulates vast amounts of online conversations that enable data-driven modeling of chat dialogues. It is, however, still hard to utilize the neural network-based SEQ2SEQ model for dialogue modeling in spite of its acknowledged success in machine translation. The main challenge comes from the high degrees of freedom of responses in dialogues. In this study, we explore neural conversational models that have general mechanisms for handling a variety of situations that affect our response. In our experiments, we confirmed the effectiveness of the proposed method in a response selection test by using massive dialogue data we have collected from Twitter.
