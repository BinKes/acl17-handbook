SubmissionNumber#=%=#484
FinalPaperTitle#=%=#Joint CTC/attention decoding for end-to-end speech recognition
ShortPaperTitle#=%=#Joint CTC/attention decoding for end-to-end speech recognition
NumberOfPages#=%=#12
CopyrightSigned#=%=#Takaaki Hori
JobTitle#==#
Organization#==#Mitsubishi Electric Research Laboratories
201 Broadway, Cambridge MA, 02139 USA
Abstract#==#End-to-end automatic speech recognition (ASR) has become a popular alternative
to conventional DNN/HMM systems because it avoids the need for linguistic
resources such as pronunciation dictionary, tokenization, and
context-dependency trees, leading to a greatly simplified model-building
process. There are two major types of end-to-end architectures for ASR: 
attention-based methods use an attention mechanism to perform alignment between
acoustic frames and recognized symbols, and connectionist temporal
classification (CTC), uses Markov assumptions to efficiently solve sequential
problems by dynamic programming. This paper proposes joint decoding algorithm
for end-to-end ASR with a hybrid CTC/attention architecture, which effectively
utilizes both advantages in decoding. We have applied the proposed method to
two ASR benchmarks (spontaneous Japanese and Mandarin Chinese), and showing the
comparable performance to conventional state-of-the-art DNN/HMM ASR systems
without linguistic resources.
Author{1}{Firstname}#=%=#Takaaki
Author{1}{Lastname}#=%=#Hori
Author{1}{Email}#=%=#thori@merl.com
Author{1}{Affiliation}#=%=#MERL
Author{2}{Firstname}#=%=#Shinji
Author{2}{Lastname}#=%=#Watanabe
Author{2}{Email}#=%=#shinjiw@ieee.org
Author{2}{Affiliation}#=%=#MERL
Author{3}{Firstname}#=%=#John
Author{3}{Lastname}#=%=#Hershey
Author{3}{Email}#=%=#john.r.hershey@gmail.com
Author{3}{Affiliation}#=%=#MERL

==========