SubmissionNumber#=%=#680
FinalPaperTitle#=%=#Leveraging Knowledge Bases in LSTMs for Improving Machine Reading
ShortPaperTitle#=%=#Leveraging Knowledge Bases in LSTMs for Improving Machine Reading
NumberOfPages#=%=#11
CopyrightSigned#=%=#Bishan Yang
JobTitle#==#
Organization#==#Carnegie Mellon University
5000 Forbes Ave, Pittsburgh, PA 15213
Abstract#==#This paper focuses on how to take advantage of external knowledge bases (KBs)
to improve recurrent neural networks for machine reading. Traditional methods
that exploit knowledge from KBs encode knowledge as discrete indicator
features. Not only do these features generalize poorly, but they require
task-specific feature engineering to achieve good performance. We propose
KBLSTM, a novel neural model that leverages continuous representations of KBs
to enhance the learning of recurrent neural networks for machine reading. To
effectively integrate background knowledge with information from the currently
processed text, our model employs an attention mechanism with a sentinel to
adaptively decide whether to attend to background knowledge and which
information from KBs is useful. Experimental results show that our model
achieves accuracies that surpass the previous state-of-the-art results for both
entity extraction and event extraction on the widely used ACE2005 dataset.
Author{1}{Firstname}#=%=#Bishan
Author{1}{Lastname}#=%=#Yang
Author{1}{Email}#=%=#bishan@cs.cmu.edu
Author{1}{Affiliation}#=%=#Carnegie Mellon University
Author{2}{Firstname}#=%=#Tom
Author{2}{Lastname}#=%=#Mitchell
Author{2}{Email}#=%=#tom.mitchell@cs.cmu.edu
Author{2}{Affiliation}#=%=#Carnegie Mellon University

==========