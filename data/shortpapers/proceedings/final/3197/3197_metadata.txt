SubmissionNumber#=%=#3197
FinalPaperTitle#=%=#Neural Semantic Parsing over Multiple Knowledge-bases
ShortPaperTitle#=%=#Neural Semantic Parsing over Multiple Knowledge-bases
NumberOfPages#=%=#6
CopyrightSigned#=%=#Jonathan Herzig
JobTitle#==#
Organization#==#Tel Aviv University, Tel-Aviv, Israel.
Abstract#==#A fundamental challenge in developing semantic parsers is the paucity of strong
supervision in the form of language utterances annotated with logical form. In
this paper, we propose to exploit structural regularities in language in
different domains, and train semantic parsers over multiple knowledge-bases
(KBs), while sharing information across datasets. We find that we can
substantially improve parsing accuracy by training a single
sequence-to-sequence model over multiple KBs, when providing an encoding of the
domain at decoding time. Our model achieves state-of-the-art performance on the
Overnight dataset (containing eight domains), improves performance over a
single KB baseline from 75.6% to 79.6%, while obtaining a 7x reduction in the
number of model parameters.
Author{1}{Firstname}#=%=#Jonathan
Author{1}{Lastname}#=%=#Herzig
Author{1}{Email}#=%=#hjon@il.ibm.com
Author{1}{Affiliation}#=%=#IBM Research
Author{2}{Firstname}#=%=#Jonathan
Author{2}{Lastname}#=%=#Berant
Author{2}{Email}#=%=#joberant@cs.tau.ac.il
Author{2}{Affiliation}#=%=#Tel-Aviv University

==========