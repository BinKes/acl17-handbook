SubmissionNumber#=%=#28
FinalPaperTitle#=%=#Semantic Frames and Visual Scenes: Learning Semantic Role Inventories from Image and Video Descriptions
ShortPaperTitle#=%=#Semantic Frames and Visual Scenes: Learning Semantic Role Inventories from Image and Video Descriptions
NumberOfPages#=%=#6
CopyrightSigned#=%=#Ekaterina Shutova
JobTitle#==#
Organization#==#
Abstract#==#Frame-semantic parsing and semantic role labelling, that aim to automatically
assign semantic roles to arguments of verbs in a sentence, have become an
active strand of research in NLP. However, to date these methods have relied on
a predefined inventory of semantic roles. In this paper, we present a method to
automatically learn argument role inventories for verbs from large corpora of
text, images and videos. We evaluate the method against manually constructed
role inventories in FrameNet and show that the visual model outperforms the
language-only model and operates with a high precision.
Author{1}{Firstname}#=%=#Ekaterina
Author{1}{Lastname}#=%=#Shutova
Author{1}{Email}#=%=#es407@cam.ac.uk
Author{1}{Affiliation}#=%=#University of Cambridge
Author{2}{Firstname}#=%=#Andreas
Author{2}{Lastname}#=%=#Wundsam
Author{2}{Email}#=%=#andi@wundsam.net
Author{2}{Affiliation}#=%=#Big Switch Networks Inc.
Author{3}{Firstname}#=%=#Helen
Author{3}{Lastname}#=%=#Yannakoudakis
Author{3}{Email}#=%=#helen.yannakoudakis@cl.cam.ac.uk
Author{3}{Affiliation}#=%=#University of Cambridge

==========